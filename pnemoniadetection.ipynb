{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pydicom\nimport time\nimport copy\nimport torchvision.models as models\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom matplotlib.patches import Rectangle\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader,Subset\nimport cv2\nDEVICE=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nDATA_DIR = \"../input/rsna-pneumonia-detection-challenge\"\nprint(torch.__version__)","execution_count":1,"outputs":[{"output_type":"stream","text":"1.5.1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = pd.read_csv(f'{DATA_DIR}/stage_2_train_labels.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_data(df,data_dir,loc,dataformat=\"dict\"):\n    \"\"\"\n    Method to read a CSV file (Pandas dataframe) and parse the \n    data into the following nested dictionary:\n\n      parsed = {\n        \n        'patientId-00': {\n            'dicom': path/to/dicom/file,\n            'label': either 0 or 1 for normal or pnuemonia, \n            'boxes': list of box(es)\n        },\n        'patientId-01': {\n            'dicom': path/to/dicom/file,\n            'label': either 0 or 1 for normal or pnuemonia, \n            'boxes': list of box(es)\n        }, ...\n\n      }\n\n    \"\"\"\n    # --- Define lambda to extract coords in list [y, x, height, width]\n    extract_box = lambda row: [row['x'], row['y'], row['width'], row['height']]#coco format topleft\n\n    parsed = {}\n    for n, row in df.iterrows():\n        # --- Initialize patient entry into parsed \n        pid = row['patientId']\n        if pid not in parsed:\n            parsed[pid] = {\n                'dicom': f'{data_dir}/stage_2_{loc}_images/{pid}.dcm',\n                'label': row['Target'],\n                'boxes': []}\n\n        # --- Add box if opacity is present\n        if parsed[pid]['label'] == 1:\n            parsed[pid]['boxes'].append(extract_box(row))\n    if dataformat == \"list\":\n        parsed = [(k,v) for k,v in parsed.items()]\n\n    return parsed","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#parsed = parse_data(df,DATA_DIR,\"train\",\"list\")","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class PneumoniaDataset(Dataset):\n    \"\"\"Pneumonia dataset\"\"\"\n    def __init__(self,data_dir,data_for,transform=None):\n            \"\"\"\n            Args :\n                    csv_file: path to _dir for csv file continin annotations\n                    csv_metadata:extra metadata like opacity\n            \"\"\"\n            \n            df = pd.read_csv(f'{data_dir}/stage_2_train_labels.csv')\n            self.parsed_data = parse_data(df,data_dir,data_for,\"list\")\n            self.transform = transform\n            \n    def __len__(self):\n            return len(self.parsed_data)\n    \n    def __getitem__(self,idx):\n        \n            if torch.is_tensor(idx):\n                idx = idx.tolist()\n            patient_id = self.parsed_data[idx][0]\n            #boxes = self.parsed_data[idx][1][\"boxes\"]\n            label = self.parsed_data[idx][1][\"label\"]\n            \n            dcm_file = self.parsed_data[idx][1][\"dicom\"]\n            dcm_data = pydicom.read_file(dcm_file)\n            image = dcm_data.pixel_array\n            image = np.stack([image] * 3, axis=2)\n           # boxes = torch.as_tensor(boxes, dtype=torch.float32)\n            image_id = torch.as_tensor([idx])\n            label = torch.as_tensor([label]).to(torch.float32)\n            \n           # target = {}\n            #target['boxes'] = boxes\n            #target['label'] = label\n            #target[\"image_id\"] = image_id\n            \n            if self.transform is not None:\n                image = {\"image\":image}\n                image = self.transform(**image)\n                image = image[\"image\"]\n                image.permute(2,0,1).to(torch.float32)\n\n            return image,label,patient_id\n    ","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transform():\n    return A.Compose([\n        A.HorizontalFlip(0.5),\n        A.Resize(224,224,p=1),\n        A.Normalize(),\n        ToTensorV2(p=1.0)\n    ])\n\ndef get_valid_transform():\n    return A.Compose([\n        A.Resize(224,224,p=1),\n        A.Normalize(),\n        ToTensorV2(p=1.0)\n    ])","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data_loaders(data_dir,batch_size,val_per):\n    \n    train_dataset = PneumoniaDataset(data_dir,\"train\",transform=get_train_transform())\n    indices = torch.randperm(len(train_dataset)).tolist()\n    val_size = int(val_per*len(train_dataset))\n    train_dataset = Subset(train_dataset,indices[:-val_size])\n    valid_dataset = PneumoniaDataset(data_dir,\"train\",transform=get_valid_transform())\n    valid_dataset = Subset(valid_dataset,indices[-val_size:])\n    print(f'train_ds size{len(train_dataset)}<>val datset size{len(valid_dataset)}')\n    train_dataloader = DataLoader(train_dataset,batch_size=batch_size,num_workers=4,shuffle=True)\n    valid_dataloader = DataLoader(valid_dataset,batch_size=batch_size,num_workers=4,shuffle=True)\n    return {\"train\":train_dataloader,\"val\":valid_dataloader}\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_model(model_path=None,pretrained=False):\n    model = models.densenet121(pretrained=pretrained)\n    num_ftrs = model.classifier.in_features\n    model.classifier = nn.Sequential(\n                                     nn.Linear(num_ftrs, 1),\n                                     nn.Sigmoid())#model.classifier = torch.nn.Linear(1024,1)\n    if model_path!=None:\n        model.load_state_dict(torch.load(model_path))\n    \n    return model","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer,scheduler, num_epochs=25):\n    since = time.time()\n\n    val_acc_history = []\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n            # Iterate over data.\n            for inputs, labels,_ in dataloaders[phase]:\n                inputs = inputs.to(DEVICE)\n                labels = labels.to(DEVICE)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    if phase == 'train':\n                        outputs  = model(inputs)\n                        loss = criterion(outputs, labels)\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n                    #ones = torch.ones(outputs.shape[0]).to(DEVICE)\n                    preds = (outputs>0.5).float()\n        \n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                       # scheduler.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += (preds == labels).float().sum()\n             #   mess+=len(labels)\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n                scheduler.step(epoch_loss)\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.001","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = initialize_model(pretrained=True).to(DEVICE)\ndata_loaders = get_data_loaders(DATA_DIR,32,0.2)","execution_count":17,"outputs":[{"output_type":"stream","text":"train_ds size21348<>val datset size5336\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Loss = nn.BCELoss()\noptim = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_x = train_model(model, data_loaders, criterion=Loss, optimizer=optim,scheduler=scheduler, num_epochs=10)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 0/9\n----------\ntrain Loss: 0.6130 Acc: 0.7428\nval Loss: 0.6191 Acc: 0.7288\n\nEpoch 1/9\n----------\ntrain Loss: 0.6129 Acc: 0.7434\nval Loss: 0.6261 Acc: 0.7180\n\nEpoch 2/9\n----------\ntrain Loss: 0.6133 Acc: 0.7422\nval Loss: 0.6198 Acc: 0.7264\n\nEpoch 3/9\n----------\ntrain Loss: 0.6127 Acc: 0.7451\nval Loss: 0.6257 Acc: 0.7170\n\nEpoch 4/9\n----------\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE=torch.device(\"cuda:0\")","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.is_available()","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"False"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"klen(torch.tensor([1,2,3]))","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"3"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}